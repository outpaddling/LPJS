.TH lpjs-submit 1
.SH NAME    \" Section header
.PP

lpjs submit \- Submit a job script

\" Convention:
\" Underline anything that is typed verbatim - commands, etc.
.SH SYNOPSIS
.PP
.nf 
.na 
lpjs submit script.lpjs
.ad
.fi

\" Optional sections
.SH "DESCRIPTION"

This is a brief reference for lpjs-submit(1).  See the Research Computing
User's Guide at https://acadix.biz/publications.php for a more complete
tutorial on using LPJS.

.B "lpjs submit"
submits a new job to the LPJS queue.

A job script is an ordinary script, which can be written in any
interpreted language that uses '#' to denote a comment.

Script can be generated using lpjs-create-script(1), which is also a
menu item in lpjs-menu(1).

LPJS job parameters are embedded in the script as comments beginning
with '#lpjs'.

When the scheduler dispatches a job to a compute node, lpjs_compd(8)
starts a chaperone process, which then runs and monitors your batch script.
Output from the chaperone and the script are saved on the submit node.

.SH REQUIRED JOB PARAMETERS

There are four parameters required for every LPJS batch script:

.TP
\fBjobs\fR
The number of jobs to queue.  The script will be run this many times,
with as many as possible running simultaneously.

.TP
\fBprocessors-per-job\fR
The number of processors to allocate for each job.  This is 1 for
serial programs and >1 where each job runs a parallel program.

.TP
\fBmin-processors-per-node\fR
The number of processors that must be on the same node.  For shared
memory parallel programs, such as OpenMP and pthreads, this must equal
processors-per-job.  It can be specified as "processors-per-job", rather than
a hard-coded number, so that you need not keep the two in sync with
future changes.

.TP
\fBmem-per-proc\fR
The amount of physical memory to allocate per processor.  Must be
followed by MiB, MB, GiB, or GB.

.SH OPTIONAL JOB PARAMETERS

.TP
\fBpush-command\fR
Command used by chaperone(8) to transfer the temporary working directory
after the job completes.  This defaults to "rsync -av %w/ %h:%d",
which transfers the contents back to the directory from which the
jobs was submitted on the submit node.

.TP
\fBlog-dir\fR
The parent directory for storing job logs (standard output and
standard error from the script and chaperone) on the submit node.
The default is LPJS-logs/script-name.

.SH PORTABILITY

Since LPJS is a portable scheduler, and cluster/grids may include
multiple operating systems, care must be taken to write scripts in
a portable way.  We generally recommend using POSIX Bourne shell,
which is supported by all Unix-like platforms.  If using other
languages, which as bash(1), perl(1), or python(1), the shebang line,
which indicates the language used by the script, must be done in
a portable manner.  Only Bourne shell (sh) is included with all Unix-like
systems.  Any other scripting language is an add-on, and may be installed
in different locations on different platforms.  We can work around this
using "#!/usr/bin/env".

.nf
.na
# These are not portable, since they use platform-specific paths
#!/bin/bash
#!/usr/bin/perl
#!/usr/bin/python

# These are portable, since /usr/bin/env is consistent across platforms
#!/usr/bin/env bash
#!/usr/bin/env perl
#!/usr/bin/env python

# This is portable, since Bourne shell is included with every platform
#!/bin/sh -e
.ad
.fi

.SH ENVIRONMENT

LPJS sets the following environment variables for use by batch scripts:

.TP
\fBPATH\fR
Prepended with LOCALBASE/bin and PREFIX/bin, as these may be different
on different compute nodes.  Where LPJS was installed via a package
manager, this provides access to all other software installed by
the same package manager.
.TP
\fBLPJS_HOME_DIR\fR
The home directory of the user on the compute node.  May be
different on different nodes.
.TP
\fBLPJS_ARRAY_INDEX\fR
The 1-base array index of each job in a job array submission.
.TP
\fBLPJS_JOB_COUNT\fR
The number of jobs in the job array submission.
.TP
\fBLPJS_PROCS_PER_JOB\fR
The value set in the script by "#lpjs processors-per-job".
.TP
\fBLPJS_MIN_PROCS_PER_NODE\fR
The value set in the script by "#lpjs min-processors-per-node".
.TP
\fBLPJS_PHYS_MIB_PER_PROCESSOR\fR
The value set in the script by "#lpjs pmem-per-proc".
.TP
\fBLPJS_USER_NAME\fR
The username of the user running the job.
.TP
\fBLPJS_PRIMARY_GROUP_NAME\fR
The primary group name of the user running the job.
.TP
\fBLPJS_SUBMIT_HOST\fR
The FQDN (fully qualified domain name / host name) from which the job
was submitted.
.TP
\fBLPJS_SUBMIT_DIRECTORY\fR
The absolute pathname of the directory on the submit node, from which
the job was submitted.
.TP
\fBLPJS_SCRIPT_NAME\fR
The filename of the batch script being run by the job.
.TP
\fBLPJS_COMPUTE_NODE\fR
The compute node running the job (same as $(hostname) or `hostname`).
.TP
\fBLPJS_JOB_LOG_DIR\fR
The path of the directory containing job terminal output, relative
to LPJS_SUBMIT_DIRECTORY.  Defaults to LPJS-logs/script-name.
.TP
\fBLPJS_PUSH_COMMAND\fR
The command used to transfer the temporary current working directory
from compute nodes that do not have direct access to the submit
directory on the submit node.  Defaults to "rsync -av %w/ %h:%d",
where %w is the temporary working directory on the compute node,
%h is the submit host, and %d is the submit directory on the
submit node.  Below is output from a job that runs
"printenv | grep LPJS_" in the batch script:

.nf
.na
LPJS_JOB_COUNT=1
LPJS_COMPUTE_NODE=TBD
LPJS_PUSH_COMMAND=rsync -av %w/ %h:%d
LPJS_PHYS_MIB_PER_PROCESSOR=9
LPJS_MIN_PROCS_PER_NODE=1
LPJS_PRIMARY_GROUP_NAME=bacon
LPJS_SUBMIT_HOST=moray.acadix.biz
LPJS_JOB_LOG_DIR=LPJS-logs/env
LPJS_USER_NAME=bacon
LPJS_SUBMIT_DIRECTORY=/home/bacon
LPJS_JOB_ID=1983
LPJS_SCRIPT_NAME=env.lpjs
LPJS_PROCS_PER_JOB=1
LPJS_ARRAY_INDEX=1
LPJS_HOME_DIR=/home/bacon
.ad
.fi

.SH EXAMPLES

.nf
.na
lpjs submit fastq-trim.lpjs
.ad
.fi

.SH FILES
.nf
.na
%%PREFIX%%/etc/lpjs/config
.ad
.fi

.SH "SEE ALSO"
lpjs-jobs(1), lpjs-cancel(1), lpjs-nodes(1)

.SH AUTHOR
.nf
.na
J. Bacon
